{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.math.unipd.it/~marcuzzi/BannerStrumentifondamentali.png)\n",
    "\n",
    "# Introduzione al Python GPU programming con Numba\n",
    "\n",
    "## Che cos'è Numba?\n",
    "- Numba è un **compilatore di funzioni Python** (sia per codice seriale su CPU che per codice parallelo su GPU)\n",
    "- Numba è un compilatore **just-in-time**: le funzioni vengono tradotte non appena vengono chiamate \n",
    "- Numba è pensato per il **calcolo scientifico**: i dati devono essere di tipo int, float, o complex, inoltre Numba fornisce supporto built-in per il trasferimento di array Numpy tra CPU e GPU\n",
    "- Numba accelera le funzioni generandone un'**implementazione per lo specifico tipo di dato** (int, float, ecc...) con cui stai lavorando, a differenza delle generiche funzioni Python che operano su tutti i tipi di dati\n",
    "- Il compilatore di Numba produce un codice ottimizzato per la tua particolare CPU/GPU, perciò le prestazioni del tuo codice possono variare a seconda della macchina che utilizzi\n",
    "\n",
    "\n",
    "NB: quando si programma in parallelo è importantissimo testare il proprio codice per assicurarsi che sia corretto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from timeit import default_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba 0.39.0\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "from numba import jit, cuda, vectorize, guvectorize\n",
    "from numba import void, uint8 , uint32, uint64, int32, int64, float32, float64, f8\n",
    "\n",
    "print(\"numba\", numba.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'GeForce GTX 1060 6GB'                              [SUPPORTED]\n",
      "                      compute capability: 6.1\n",
      "                           pci device id: 0\n",
      "                              pci bus id: 1\n",
      "Summary:\n",
      "\t1/1 devices are supported\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(cuda.detect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in uso:  b'GeForce GTX 1060 6GB'\n",
      "Compute capability:  6.1 (Numba richiede >= 3.0)\n",
      "Numero di Streaming Multiprocessors: 10\n",
      "Numero di cores per SM: 128\n",
      "Numero di cores della GPU: 1280\n"
     ]
    }
   ],
   "source": [
    "my_gpu = cuda.get_current_device()\n",
    "print(\"GPU in uso: \", my_gpu.name)\n",
    "def cores_per_capability(cc): \n",
    "    if cc[0] == 3:\n",
    "        return 192\n",
    "    if cc[0] == 5:\n",
    "        return 128\n",
    "    if cc[0] == 6:\n",
    "        if cc[1] == 0:\n",
    "            return 64 \n",
    "        else:\n",
    "            return 128\n",
    "    if cc[0] == 7:\n",
    "        return 64\n",
    "cc = my_gpu.compute_capability\n",
    "print(\"Compute capability: \", \"%d.%d\" % cc, \"(Numba richiede >= 3.0)\")\n",
    "print(\"Numero di Streaming Multiprocessors:\", my_gpu.MULTIPROCESSOR_COUNT)\n",
    "cores_per_multiprocessor = cores_per_capability(cc)\n",
    "print(\"Numero di cores per SM:\", cores_per_multiprocessor)\n",
    "total_cores = cores_per_multiprocessor * my_gpu.MULTIPROCESSOR_COUNT\n",
    "print(\"Numero di cores della GPU:\", total_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipi\n",
    "\n",
    "I tipi di dati supportati da Numba sono i seguenti:\n",
    "\n",
    "-   int\n",
    "-   float\n",
    "-   complex\n",
    "-   bool\n",
    "-   None\n",
    "-   tuple\n",
    "\n",
    "NB: **non** sono supportati gli oggetti.\n",
    "\n",
    "Le seguenti funzioni built-in sono supportate:\n",
    "\n",
    "-    abs()\n",
    "-    bool\n",
    "-    complex\n",
    "-    enumerate()\n",
    "-    float\n",
    "-    int: solo la versione con un unico argomento \n",
    "-    len()\n",
    "-    min(): solo la versione con argomenti multipli \n",
    "-    max(): solo la versione con argomenti multipli\n",
    "-    range: viene riportato un oggetto range invece di un array di valori.\n",
    "-    round()\n",
    "-    zip()\n",
    "\n",
    "\n",
    "Inoltre, sono supportate alcune funzioni dei moduli `math` (numeri reali) e `cmath` (numeri complessi). Per la lista completa vai su: https://numba.pydata.org/numba-doc/dev/cuda/cudapysupported.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Il decoratore @vectorize\n",
    ">Converte una funzione tra scalari in una funzione vettoriale che agisce su di un array elemento per elemento. Molte delle funzioni di Numpy sono di questo tipo, come ad esempio `np.sin()`, `np.cos()`, `np.exp()`, e così via. \n",
    "\n",
    "La keyword target può prendere i seguenti valori\n",
    "- cpu: crea una funzione seriale (ma ottimizzata) per la CPU\n",
    "- parallel: crea una funzione parallela che viene eseguita su una multi-core CPU\n",
    "- cuda: crea una funzione massivamente parallela per GPU\n",
    "\n",
    "Noi ci concentreremo sul caso `target = cuda`. In questo caso, il compilatore Numba richiede che venga specificata la lista delle *segnature supportate dalla funzione*, cioè il tipo dei dati in input e in output. Una funzione che, ad esempio, prende in input due scalari `float32` e restutuisce un `float32` avrà segnatura `float32(float32, float32)`. Si posso specificare diverse segnature per otterene diverse copie della stessa funzione ottimizzate a seconda del tipo di dato. In questo caso le segnature vanno ordinate **da quella meno inclusiva a quella piu' inclusiva**.\n",
    "\n",
    "Scriviamo una funzione che dati due array $x,y$ calcoli il vettore\n",
    "\n",
    "$$ z[i] = sin(x[i])*exp(y[i]).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versione CPU\n",
    "@numba.vectorize(['float32(float32, float32)',\n",
    "                  'float64(float64, float64)'], target='cpu')\n",
    "def sinexp_cpu(x, y):\n",
    "    return math.sin(x) * math.exp(y)\n",
    "\n",
    "# Versione CUDA\n",
    "@numba.vectorize(['float32(float32, float32)',\n",
    "                     'float64(float64, float64)'], target='cuda')\n",
    "def sinexp_cuda(x, y):\n",
    "    return math.sin(x) * math.exp(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generazione dei dati\n",
    "n = 1000000\n",
    "x = np.linspace(0, 2*np.pi, n)\n",
    "y = np.linspace(10, 10, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU vectorize e' corretto:  True\n",
      "GPU vectorize e' corretto:  True\n"
     ]
    }
   ],
   "source": [
    "# Verifica del risultato\n",
    "np_ans = np.sin(x) * np.exp(y)\n",
    "cpu_ans = sinexp_cpu(x, y)\n",
    "cuda_ans = sinexp_cuda(x, y)\n",
    "\n",
    "print(\"CPU vectorize e' corretto: \", np.allclose(cpu_ans, np_ans))\n",
    "print(\"GPU vectorize e' corretto: \", np.allclose(cuda_ans, np_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo Numpy\n",
      "47.1 ms ± 77.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Tempo CPU vectorize\n",
      "41.7 ms ± 204 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Tempo GPU vectorize\n",
      "6.85 ms ± 13.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tempo Numpy\")\n",
    "%timeit np.sin(x) * np.exp(y)\n",
    "\n",
    "print(\"Tempo CPU vectorize\")\n",
    "%timeit sinexp_cpu(x, y)\n",
    "\n",
    "print(\"Tempo GPU vectorize\")\n",
    "%timeit sinexp_cuda(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed-up di CPU vectorize vs Numpy =  1.3654832173812843\n",
      "speed-up di GPU vectorize vs Numpy =  12.613158023239503\n"
     ]
    }
   ],
   "source": [
    "#speed-up\n",
    "t_i = default_timer()\n",
    "np.sin(x) * np.exp(y)\n",
    "t_f = default_timer()\n",
    "np_time = t_f -t_i\n",
    "\n",
    "t_i = default_timer()\n",
    "sinexp_cpu(x, y)\n",
    "t_f = default_timer()\n",
    "cpu_time = t_f -t_i\n",
    "\n",
    "t_i = default_timer()\n",
    "sinexp_cuda(x, y)\n",
    "t_f = default_timer()\n",
    "cuda_time = t_f -t_i\n",
    "\n",
    "print('speed-up di CPU vectorize vs Numpy = ', np_time/cpu_time )\n",
    "print('speed-up di GPU vectorize vs Numpy = ', np_time/cuda_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosa succede a basso livello?\n",
    "- Trasferimenti in memoria automatizzati:\n",
    "    gli array di Numpy vengono automatimente trasferiti in entrambe le direzioni\n",
    "     - CPU -> GPU\n",
    "     - GPU -> CPU\n",
    "    Tuttavia è possibile gestire esplicitamente queste operazioni.\n",
    "- Distribuzione del lavoro automatizzata:\n",
    "    il lavoro viene distribuito in maniera automatica tra i processori della GPU.\n",
    "\n",
    "- Gestione della memoria GPU automatizzata:\n",
    "    la memoria della GPU viene allocata e liberata in maniera del tutto automatica.\n",
    "\n",
    "## Gestire la memoria manualmente sulla GPU\n",
    "\n",
    "Per allocare memoria sulla GPU ci sono due chiamate:\n",
    "-  numba.cuda.device_array alloca senza inizializzare la memoria necessaria per un array con type e shape specifici (simile a numpy.empty)\n",
    "-  numba.cuda.device_array_like alloca senza inizializzare la memoria necessaria per un array con type e shape di un altro array (simile a numpy.empty_like)\n",
    "Se invece vogliamo trasferire sulla memoria del device un array CPU:\n",
    "- numba.cuda.to_device crea una copia GPU di un array CPU\n",
    "\n",
    "Queste chiamate restituiscono un oggetto Device Array\n",
    "\n",
    "    class numba.cuda.cudadrv.devicearray.DeviceNDArray(shape, strides, dtype, stream=0, writeback=None, gpu_data=None)\n",
    "\n",
    "Attraverso alcune chiamate ai metodi di quest'oggetto possiamo copiarlo in memoria CPU o GPU:\n",
    "- GPU -> GPU / CPU -> GPU: self.copy_to_device(ary) copia ary in self. Se ary è un array GPU effettua un trasferimento device-to-device, se ary è un array CPU effettua un trasferimento host-to-device. \n",
    "- GPU -> CPU: self.copy_to_host(ary) copia self in ary se ary è un array CPU, crea un nuovo array Numpy se altrimenti ary è None.\n",
    "\n",
    "Trasferiamo manualmente la memoria sulla GPU per vedere qual è il tempo di calcolo effettivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = cuda.device_array_like(x) # oppure numba.device_array((n,))\n",
    "dx = cuda.to_device(x)\n",
    "dy = cuda.to_device(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 ms ± 880 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def check_pure_compute_time(dx, dy, dz):\n",
    "    dz = sinexp_cuda(dx, dy)\n",
    "    cuda.synchronize()   # assicura che il calcolo sia concluso\n",
    "    \n",
    "%timeit check_pure_compute_time(dx, dy, dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il tempo di calcolo effettivo è minore di quello che avevamo misurato!\n",
    "I trasferimenti in memoria sono molto costosi.\n",
    "\n",
    "** Se si devono eseguire molti calcoli (ad. es. molto chiamate a funzioni vectorize), è meglio trasferire i dati manualmente un'unica volta prima delle chiamate. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copio in host memory\n",
    "z = dz.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dx, dy, dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Il decoratore @guvectorize\n",
    "> Il decoratore vectorize permette di scrivere funzioni che agiscono sui singoli elementi di un array, ma a volte questo è limitante. Il decoratore guvectorize permette di scrivere funzioni che lavorano su un numero arbitrario di elementi, e permette che gli array in input e output possano avere dimensioni diverse. Le funzioni compilate con guvectorize *non* ritornano alcun risultato, che inceve viene scritto riempendo un array che viene passato come **ultimo argomento in input**.\n",
    "\n",
    "\n",
    "Il decoratore guvectorize inoltre richiede\n",
    "- la lista ordinata delle segnature supportate (NB: dato che non ritornano alcun risultato, è necessario specificare solo il tipo dei dati in input)\n",
    "- la dichiarazione simbolica delle dimensioni di input e output (NB: output = l'ultima variabile in input): ad esempio, una funzione che prende in input un array 1d di dimensione `n` e uno scalare e ritorna un array 1d di dimensione n si dichiarerà come `(n),()->(n)` (le parentesi vuote indicano lo scalare)\n",
    "\n",
    "Scriviamo una funzione che data una matrice $A$ di dimensione $(n,m)$ ritorna il vettore $s$ di lunghezza $n$ definito da\n",
    "\n",
    "$$ s[i] = \\sum_{j = 1}^{m} A_{ij}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@guvectorize(['void(int32[:,:], int32[:])', 'void(float32[:,:], float32[:])'], '(n,m)->(n)', target='cuda')\n",
    "def sum_row(A, s):\n",
    "    for i in range(A.shape[0]):\n",
    "        tmp = 0.\n",
    "        for j in range(A.shape[1]):\n",
    "            tmp += A[i,j]\n",
    "        #endfor\n",
    "        s[i] = tmp\n",
    "    #endfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU guvectorize e' corretto: True\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "a = np.random.random(n*n).astype(np.float32).reshape(n,n)\n",
    "\n",
    "np_ans = np.sum(a, axis = 1)\n",
    "gvec_ans = sum_row(a)\n",
    "\n",
    "print(\"GPU guvectorize e' corretto:\", np.allclose(np_ans, gvec_ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Il decoratore @reduce\n",
    "> Numba fornisce il decoratore reduce che converte un'operazione binaria in una funzione per la riduzione di array 1d.\n",
    "\n",
    "Scriviamo una funzione che dato un vettore $x$ calcola\n",
    "$$ s = \\prod_i x[i].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.reduce\n",
    "def prod_reduce(a, b):\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU reduce e' corretto:  True\n"
     ]
    }
   ],
   "source": [
    "# Generazione dei dati\n",
    "n = 4000000\n",
    "x = np.random.random(n) #(np.arange(n, dtype=np.float64)) + 1\n",
    "\n",
    "\n",
    "np_ans = np.prod(x)      # riduzione numpy\n",
    "gpu_ans = prod_reduce(x)   # riduzione cuda\n",
    "print(\"GPU reduce e' corretto: \", np.allclose(np_ans, gpu_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
